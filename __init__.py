import os
import json
import aiohttp
from bs4 import BeautifulSoup
from hoshino import Service, priv, util
from hoshino.typing import CQEvent, MessageSegment

sv = Service('æŸ¥ç•ª', help_='AGEåŠ¨æ¼«ç•ªå‰§æœç´¢æ’ä»¶\nç”¨æ³•ï¼šæŸ¥ç•ª ç•ªå‰§åç§°', enable_on_default=False)

# é…ç½®æ–‡ä»¶
from .config import HEADERS, CACHE_DIR, SSL_CONTEXT

os.makedirs(CACHE_DIR, exist_ok=True)

def _get_cache_path(user_id: str) -> str:
    return os.path.join(CACHE_DIR, f"{user_id}.json")

def _save_cache(user_id: str, data: dict):
    cache_path = _get_cache_path(user_id)
    with open(cache_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def _load_cache(user_id: str) -> dict:
    cache_path = _get_cache_path(user_id)
    if not os.path.exists(cache_path):
        return None
    with open(cache_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def _build_anime_message(anime: dict):
    # è¿”å›æ¶ˆæ¯æ®µåˆ—è¡¨è€Œä¸æ˜¯æ‹¼æ¥å­—ç¬¦ä¸²
    msg = []
    if anime.get('å°é¢å›¾'):
        msg.append(MessageSegment.image(anime['å°é¢å›¾']))
    
    text_content = [
        f"ğŸ“º æ ‡é¢˜ï¼š{anime['æ ‡é¢˜']}",
        f"â± é¦–æ’­ï¼š{anime['é¦–æ’­æ—¶é—´']}",
        f"ğŸ“ ç®€ä»‹ï¼š{anime['ç®€ä»‹'][:100]}...",
        f"ğŸ”— è¯¦æƒ…ï¼š{anime['è¯¦æƒ…é“¾æ¥']}"
    ]
    
    if anime.get('æ’­æ”¾é“¾æ¥'):
        text_content.append(f"â–¶ï¸ æ’­æ”¾ï¼š{anime['æ’­æ”¾é“¾æ¥']}")
    
    msg.append(MessageSegment.text('\n'.join(text_content)))
    return msg

async def _fetch_search_results(keyword: str) -> str:
    url = 'https://www.agedm.org/search'
    conn = aiohttp.TCPConnector(ssl=SSL_CONTEXT)
    async with aiohttp.ClientSession(headers=HEADERS, connector=conn) as session:
        async with session.get(url, params={'query': keyword, 'page': 1}) as resp:
            resp.raise_for_status()
            return await resp.text()

def _parse_results(html: str, keyword: str) -> dict:
    soup = BeautifulSoup(html, 'html.parser')
    anime_list = []

    for item in soup.find_all('div', class_='cata_video_item'):
        title_tag = item.find('h5')
        if not title_tag:
            continue

        cover_img = item.find('img', class_='video_thumbs')
        play_btn = item.find('a', class_='btn-danger')

        anime = {
            'æ ‡é¢˜': title_tag.text.strip(),
            'è¯¦æƒ…é“¾æ¥': title_tag.a['href'] if title_tag.a else '',
            'é¦–æ’­æ—¶é—´': _extract_detail(item, 'é¦–æ’­æ—¶é—´'),
            'ç®€ä»‹': _extract_detail(item, 'ç®€ä»‹'),
            'å°é¢å›¾': cover_img['data-original'] if cover_img else '',
            'æ’­æ”¾é“¾æ¥': play_btn['href'] if play_btn else ''
        }
        anime_list.append(anime)

    return {'ç•ªå‰§åˆ—è¡¨': anime_list}

def _extract_detail(soup, field: str) -> str:
    field_span = soup.find('span', string=lambda t: t and t.strip().startswith(f"{field}ï¼š"))
    if not field_span:
        return ''

    detail_div = field_span.find_parent('div', class_='video_detail_info')
    field_span.extract()
    return detail_div.get_text(strip=True)

@sv.on_prefix('æŸ¥ç•ª')
async def search_anime(bot, ev: CQEvent):
    keyword = ev.message.extract_plain_text().strip()
    if not keyword:
        await bot.send(ev, "è¯·è¾“å…¥è¦æŸ¥è¯¢çš„ç•ªå‰§åç§°ï¼Œä¾‹å¦‚ï¼šæŸ¥ç•ª é®å¤©")
        return

    try:
        html = await _fetch_search_results(keyword)
        result = _parse_results(html, keyword)
        anime_list = result['ç•ªå‰§åˆ—è¡¨']
        total = len(anime_list)

        if total == 0:
            await bot.send(ev, f"æœªæ‰¾åˆ°ä¸ã€Œ{keyword}ã€ç›¸å…³çš„ç•ªå‰§")
            return

        if total > 2:
            page_size = 2
            total_pages = (total + page_size - 1) // page_size
            cache_data = {
                "keyword": keyword,
                "all_results": anime_list,
                "total_pages": total_pages,
                "current_page": 1,
                "page_size": page_size
            }
            _save_cache(ev.user_id, cache_data)

            await bot.send(ev, f"ğŸ”æ‰¾åˆ°{total}æ¡ç»“æœï¼ˆç¬¬1/{total_pages}é¡µï¼‰")
            for anime in anime_list[:page_size]:
                for msg_seg in _build_anime_message(anime):
                    await bot.send(ev, msg_seg)
            await bot.send(ev, "è¾“å…¥ ä¸‹ä¸€é¡µ ç»§ç»­æŸ¥çœ‹ï¼Œä¸Šä¸€é¡µ è¿”å›")
        else:
            await bot.send(ev, f"æ‰¾åˆ°{total}æ¡ç»“æœï¼š")
            for anime in anime_list:
                for msg_seg in _build_anime_message(anime):
                    await bot.send(ev, msg_seg)

    except Exception as e:
        sv.logger.error(f"æœç´¢å¤±è´¥: {str(e)}", exc_info=True)
        await bot.send(ev, "ç•ªå‰§æŸ¥è¯¢æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•")

@sv.on_keyword('ä¸‹ä¸€é¡µ')
async def next_page(bot, ev: CQEvent):
    cache = _load_cache(ev.user_id)
    if not cache:
        await bot.send(ev, "è¯·å…ˆä½¿ç”¨ã€æŸ¥ç•ªã€‘è¿›è¡Œæœç´¢")
        return

    current_page = cache['current_page'] + 1
    if current_page > cache['total_pages']:
        await bot.send(ev, "å·²ç»æ˜¯æœ€åä¸€é¡µäº†")
        return

    start = (current_page - 1) * cache['page_size']
    page_data = cache['all_results'][start:start + cache['page_size']]

    cache['current_page'] = current_page
    _save_cache(ev.user_id, cache)

    await bot.send(ev, f"ğŸ“–ç¬¬{current_page}/{cache['total_pages']}é¡µ")
    for anime in page_data:
        for msg_seg in _build_anime_message(anime):
            await bot.send(ev, msg_seg)
    if current_page < cache['total_pages']:
        await bot.send(ev, "è¾“å…¥ã€ä¸‹ä¸€é¡µã€‘ç»§ç»­æŸ¥çœ‹ï¼Œã€ä¸Šä¸€é¡µã€‘è¿”å›")

@sv.on_keyword('ä¸Šä¸€é¡µ')
async def prev_page(bot, ev: CQEvent):
    cache = _load_cache(ev.user_id)
    if not cache:
        await bot.send(ev, "è¯·å…ˆä½¿ç”¨ã€æŸ¥ç•ªã€‘è¿›è¡Œæœç´¢")
        return

    current_page = cache['current_page'] - 1
    if current_page < 1:
        await bot.send(ev, "å·²ç»æ˜¯ç¬¬ä¸€é¡µäº†")
        return

    start = (current_page - 1) * cache['page_size']
    page_data = cache['all_results'][start:start + cache['page_size']]

    cache['current_page'] = current_page
    _save_cache(ev.user_id, cache)

    await bot.send(ev, f"ğŸ“–ç¬¬{current_page}/{cache['total_pages']}é¡µ")
    for anime in page_data:
        for msg_seg in _build_anime_message(anime):
            await bot.send(ev, msg_seg)
    await bot.send(ev, "è¾“å…¥ã€ä¸‹ä¸€é¡µã€‘ç»§ç»­æŸ¥çœ‹ï¼Œã€ä¸Šä¸€é¡µã€‘è¿”å›")